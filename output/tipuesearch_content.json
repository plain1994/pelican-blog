{"pages":[{"url":"/spark-160-dan-ji-an-zhuang-pei-zhi.html","text":"本文将介绍Apache Spark 1.6.0在单机的部署，与在集群中部署的步骤基本一致，只是少了一些master和slave文件的配置。 0.Spark的安装准备 Spark官网的文档 http://spark.apache.org/docs/latest/ 里是这样说的： Spark runs on Java 7+, Python 2.6+ and R 3.1+. For the Scala API, Spark 1.6.0 uses Scala 2.10. You will need to use a compatible Scala version (2.10.x). 我的电脑环境是Ubuntu 14.04.4 LTS，还需要安装： jdk-8u73-linux-x64.tar.gz hadoop-2.6.0.tar.gz scala-2.10.6.tgz spark-1.6.0-bin-hadoop2.6.tgz 1.安装jdk 解压jdk安装包到任意目录： cd /home/tom $ tar -xzvf jdk-8u73-linux-x64.tar.gz $ sudo vim /etc/profile 编辑/etc/profile文件，在最后加上java环境变量： export JAVA_HOME=/home/tom/jdk1.8.0_73/ export JRE_HOME=/home/tom/jdk1.8.0_73/jre export PATH= $ JAVA_HOME /bin: $ JRE_HOME /bin: $ PATH export CLASSPATH=.: $ JAVA_HOME /lib: $ JRE_HOME /lib: $ CLASSPATH 保存并更新 /etc/profile ： $ source /etc/profil 查看是否成功： $ java -version 2.配置ssh localhost 确保安装好ssh： $ sudo apt-get update $ sudo apt-get install openssh-server $ sudo /etc/init.d/ssh start 生成并添加密钥： $ ssh-keygen -t rsa $ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys $ chmod 0600 ~/.ssh/authorized_keys 如果已经生成过密钥，只需执行后两行命令。 测试ssh localhost $ ssh localhost $ exit 3.安装hadoop2.6.0 解压hadoop2.6.0到任意目录： $ cd /home/tom $ wget http://apache.claz.org/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz $ tar -xzvf hadoop-2.6.0.tar.gz 编辑 /etc/profile 文件，在最后加上java环境变量： export HADOOP_HOME=/home/tom/hadoop-2.6.0 export HADOOP_INSTALL= $ HADOOP_HOME export HADOOP_MAPRED_HOME= $ HADOOP_HOME export HADOOP_COMMON_HOME= $ HADOOP_HOME export HADOOP_HDFS_HOME= $ HADOOP_HOME export YARN_HOME= $ HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR= $ HADOOP_HOME /lib/native export PATH= $ PATH : $ HADOOP_HOME /sbin: $ HADOOP_HOME /bin 编辑 $HADOOP_HOME/etc/hadoop/hadoop-env.sh 文件 $ vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh 在最后加上： export JAVA_HOME=/home/tom/jdk1.8.0_73/ 修改Configuration文件： $ cd $HADOOP_HOME/etc/hadoop 修改 core-site.xml ： <configuration> <property> <name> fs.default.name </name> <value> hdfs://localhost:9000 </value> </property> </configuration> 修改 hdfs-site.xml ： <configuration> <property> <name> dfs.replication </name> <value> 1 </value> </property> <property> <name> dfs.name.dir </name> <value> file:///home/tom/hadoopdata/hdfs/namenode </value> </property> <property> <name> dfs.data.dir </name> <value> file:///home/tom/hadoopdata/hdfs/datanode </value> </property> </configuration> 第一个是dfs的备份数目，单机用1份就行，后面两个是namenode和datanode的目录。 修改 mapred-site.xml ： <configuration> <property> <name> mapreduce.framework.name </name> <value> yarn </value> </property> </configuration> 修改 yarn-site.xml ： <configuration> <property> <name> yarn.nodemanager.aux-services </name> <value> mapreduce_shuffle </value> </property> </configuration> 初始化hadoop： $ hdfs namenode -format 启动 $ $HADOOP_HOME/sbin/start-all.sh 停止 $ $HADOOP_HOME/sbin/stop-all.sh 检查WebUI，浏览器打开端口： http://localhost:8088 port 8088: cluster and all applications port 50070: Hadoop NameNode port 50090: Secondary NameNode port 50075: DataNode hadoop运行后可使用 jps 命令查看,得到结果： 10057 Jps 9611 ResourceManager 9451 SecondaryNameNode 9260 DataNode 9102 NameNode 9743 NodeManager 4.安装scala 解压scala安装包到任意目录： $ cd /home/tom $ tar -xzvf scala-2.10.6.tgz $ sudo vim /etc/profile 在 /etc/profile 文件的末尾添加环境变量： export SCALA_HOME=/home/tom//scala-2.10.6 export PATH= $ SCALA_HOME /bin: $ PATH 保存并更新 /etc/profile ： $ source /etc/profil 查看是否成功： $ scala -version 5.安装Spark 解压spark安装包到任意目录： $ cd /home/tom $ tar -xzvf spark-1.6.0-bin-hadoop2.6.tgz $ mv spark-1.6.0-bin-hadoop2.6 spark-1.6.0 $ sudo vim /etc/profile 在 /etc/profile 文件的末尾添加环境变量： export SPARK_HOME=/home/tom/spark-1.6.0 export PATH= $ SPARK_HOME /bin: $ PATH 保存并更新 /etc/profile ： $ source /etc/profil 在conf目录下复制并重命名 spark-env.sh.template 为 spark-env.sh ： $ cp spark-env.sh.template spark-env.sh $ vim spark-env.sh 在 spark-env.sh 中添加： export JAVA_HOME=/home/tom/jdk1.8.0_73/ export SCALA_HOME=/home/tom//scala-2.10.6 export SPARK_MASTER_IP=localhost export SPARK_WORKER_MEMORY=4G 启动 $ $SPARK_HOME/sbin/start-all.sh 停止 $ $SPARK_HOME/sbin/stop-all.sh 测试Spark是否安装成功： $ $SPARK_HOME/bin/run-example SparkPi 得到结果： Pi is roughly 3.14716 检查WebUI，浏览器打开端口： http://localhost:8080","tags":"Blogs","title":"Spark 1.6.0 单机安装配置"},{"url":"/c-review1.html","text":"1.数据类型 type byte bit 有效数字 int 4bytes 32bits(-2&#94;31 ~ 2&#94;31-1) short 2bytes 16bits long 4bytes 32bits unsigned 4bytes 32bits(0～2&#94;32-1) bool 1byte char 1byte float 4bytes 32bits(-2&#94;128 ~ 2&#94;128) 6~7 double 8bytes 64bits(-2&#94;1024 ~ 2&#94;1024) 15~16 long double 16bytes 18~19 注意： long int 和 int在16位以上机器相同，均为32位，16位机器int为16位 bool值有两种true和false，字节值为1或0 char一个字节，字节中存放的是对应字符的ASCII值，如 'A' 实型数（浮点型）在计算机内不能精确表示。 其中float4字节，32位，符号位1位，指数位8位，于是float的指数范围为-127~128。float尾数部分23位，2&#94;23 = 8388608，一共七位，这意味着float最多能有7位有效数字，但绝对能保证的为6位。 可以通过 sizeof() 了解不同类型占用多少内存量（字节）： #include <iostream> int main () { std :: cout << sizeof ( float ) << std :: endl ; std :: cout << sizeof ( double ) << std :: endl ; std :: cout << sizeof ( long double ) << std :: endl ; return 0 ; } 执行结果： 4 8 16 123e3,123E3(科学计数法 123*10&#94;3 ) 一维数组 int a[10]; 二维数组 int a[4][5];//4*5 字符串 char ch[] = \"Hello,world\"; 或 char ch[] = {\"Hello,world\"}; 或 char ch[] = {'H','e','l','l','o',',','w','o','r','l','d','\\0'}; == 以 '\\0' 为结束符 == 'a' 与 \"a\" ： 'a' 为字符常量，一字节（a的ASCII值）； \"a\" 为字符串，2字节（a的ASCII值和'\\0'） 字符串处理函数 #include<cstring> strcpy(dst, src) strlen(s) strchr(s, ch) strcmp(s1, s2) enum枚举 enum weekdayT{SUnday, Monday}; 2.基础知识 位，比特，bit(二进制的一位) 字节，byte，B（8个位组成一个字节） 注释 //一行的注释 /*多行 的注释 */ 库包含 #include <iostream> #include \"user.h\" //自己写的库user 宏定义 #define PI 3.14159 转义 '\\n' 换行 '\\t' Tab '\\\\' 反斜杠 内存量 sizeof() 符号常量 const double PI = 3.1415926 数学函数库 #include <cmath> int abs ( int x ); double fabs ( double x ); double exp ( double x ); double sqrt ( double x ); 自增自减运算 y = x ++ ; //先 y = x，再x++ y = ++ x ; 输入输出 cin >> a ; cin . get (); cin . getline ( ch1 , 80 , '.' ); //字符串输入（,数组长度,结束标记） cout << a << endl ; 主程序 //#include <iostream> using namespace std ; //名字空间 int main () { cout << \"Hello world!\" << endl ; return 0 ; } 条件句 < 小于 <= 小于等于 == == 等于 == != 不等于 逻辑运算 && 与 || 或 ! 非 3.控制流 if语句 if ( ) XXX ; else { XXX ; XXX ; } 条件表达式?: max = ( x > y ) ? x : y ; switch语句 switch (){ case const1 : XXX ; break ; case const2 : XXX ; break ; default : XXX ; break ; } for循环 for ( i = 0 ; i < n ; ++ i ){ XXX ; } while循环 while ( ){ XXX ; } do-while循环 do { XXX ; } while ( ); 循环中途退出 while ( ){ XXX ; if ( ) break ; } 随机数 #include <cstdlib> #include <ctime> srand ( time ( NULL )); //随机种子初始化 num1 = rand () * 10 / ( RAND_MAX + 1 ); num2 = rand () * 4 / ( RAND_MAX + 1 );","tags":"Blogs","title":"C++ Review(1)"}]}